{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cartoongan-impl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WgQ1lxkpkbLccBITQUsaO6k2J6JWt2ww",
      "authorship_tag": "ABX9TyM1mfPWNgjzFk9VrdW6gxjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/pg-toons/blob/master/cartoongan_impl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmDVaw7HqWmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbf80055-f5a5-4051-a08f-55312c2e964b"
      },
      "source": [
        "!rm -r keras-contrib/ \n",
        "# !pip uninstall -y tensorflow-gpu==2.0.0-alpha0\n",
        "# !pip uninstall -y tensorflow\n",
        "# !pip install tensorflow-gpu==2.0.0-alpha0\n",
        "!git clone https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && cd keras-contrib \\\n",
        "    && pip install git+https://www.github.com/keras-team/keras-contrib.git \\\n",
        "    && python convert_to_tf_keras.py \\\n",
        "    && USE_TF_KERAS=1 python setup.py install\n",
        "# clear_output()\n",
        "!pip install -q  --no-deps tensorflow-addons~=0.7"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-contrib'...\n",
            "warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "remote: Enumerating objects: 3634, done.\u001b[K\n",
            "remote: Total 3634 (delta 0), reused 0 (delta 0), pack-reused 3634\u001b[K\n",
            "Receiving objects: 100% (3634/3634), 861.24 KiB | 13.46 MiB/s, done.\n",
            "Resolving deltas: 100% (2330/2330), done.\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-b59vlok1\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-b59vlok1\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=7699caad97092b4281f616fedda6a751754148365d1a06a5fe49172af13249ba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e0at2rl6/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Changed imports in 73 files.\n",
            "Those files were found in the directory /content/keras-contrib\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating tf_keras_contrib.egg-info\n",
            "writing tf_keras_contrib.egg-info/PKG-INFO\n",
            "writing dependency_links to tf_keras_contrib.egg-info/dependency_links.txt\n",
            "writing requirements to tf_keras_contrib.egg-info/requires.txt\n",
            "writing top-level names to tf_keras_contrib.egg-info/top_level.txt\n",
            "writing manifest file 'tf_keras_contrib.egg-info/SOURCES.txt'\n",
            "writing manifest file 'tf_keras_contrib.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/keras_contrib\n",
            "copying keras_contrib/__init__.py -> build/lib/keras_contrib\n",
            "creating build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/test_utils.py -> build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/__init__.py -> build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/save_load_utils.py -> build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/conv_utils.py -> build/lib/keras_contrib/utils\n",
            "creating build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/__init__.py -> build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/jaccard.py -> build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/dssim.py -> build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/crf_losses.py -> build/lib/keras_contrib/losses\n",
            "creating build/lib/keras_contrib/metrics\n",
            "copying keras_contrib/metrics/crf_accuracies.py -> build/lib/keras_contrib/metrics\n",
            "copying keras_contrib/metrics/__init__.py -> build/lib/keras_contrib/metrics\n",
            "creating build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/yogi.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/__init__.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/padam.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/ftml.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/lars.py -> build/lib/keras_contrib/optimizers\n",
            "creating build/lib/keras_contrib/preprocessing\n",
            "copying keras_contrib/preprocessing/__init__.py -> build/lib/keras_contrib/preprocessing\n",
            "creating build/lib/keras_contrib/regularizers\n",
            "copying keras_contrib/regularizers/__init__.py -> build/lib/keras_contrib/regularizers\n",
            "creating build/lib/keras_contrib/constraints\n",
            "copying keras_contrib/constraints/clip.py -> build/lib/keras_contrib/constraints\n",
            "copying keras_contrib/constraints/__init__.py -> build/lib/keras_contrib/constraints\n",
            "creating build/lib/keras_contrib/activations\n",
            "copying keras_contrib/activations/squash.py -> build/lib/keras_contrib/activations\n",
            "copying keras_contrib/activations/__init__.py -> build/lib/keras_contrib/activations\n",
            "creating build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/__init__.py -> build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/conll2000.py -> build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/pascal_voc.py -> build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/coco.py -> build/lib/keras_contrib/datasets\n",
            "creating build/lib/keras_contrib/initializers\n",
            "copying keras_contrib/initializers/__init__.py -> build/lib/keras_contrib/initializers\n",
            "copying keras_contrib/initializers/convaware.py -> build/lib/keras_contrib/initializers\n",
            "creating build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/activations.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/__init__.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/optimizers.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/metrics.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/regularizers.py -> build/lib/keras_contrib/tests\n",
            "creating build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/__init__.py -> build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/core.py -> build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/crf.py -> build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/capsule.py -> build/lib/keras_contrib/layers\n",
            "creating build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/densenet.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/__init__.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/resnet.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/nasnet.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/wide_resnet.py -> build/lib/keras_contrib/applications\n",
            "creating build/lib/keras_contrib/wrappers\n",
            "copying keras_contrib/wrappers/__init__.py -> build/lib/keras_contrib/wrappers\n",
            "creating build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/cyclical_learning_rate.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/__init__.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/dead_relu_detector.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/tensorboard.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/snapshot.py -> build/lib/keras_contrib/callbacks\n",
            "creating build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/cntk_backend.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/tensorflow_backend.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/__init__.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/numpy_backend.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/theano_backend.py -> build/lib/keras_contrib/backend\n",
            "creating build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/swish.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/sinerelu.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/srelu.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/__init__.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/pelu.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "creating build/lib/keras_contrib/layers/normalization\n",
            "copying keras_contrib/layers/normalization/instancenormalization.py -> build/lib/keras_contrib/layers/normalization\n",
            "copying keras_contrib/layers/normalization/__init__.py -> build/lib/keras_contrib/layers/normalization\n",
            "copying keras_contrib/layers/normalization/groupnormalization.py -> build/lib/keras_contrib/layers/normalization\n",
            "creating build/lib/keras_contrib/layers/convolutional\n",
            "copying keras_contrib/layers/convolutional/__init__.py -> build/lib/keras_contrib/layers/convolutional\n",
            "copying keras_contrib/layers/convolutional/cosineconvolution2d.py -> build/lib/keras_contrib/layers/convolutional\n",
            "copying keras_contrib/layers/convolutional/subpixelupscaling.py -> build/lib/keras_contrib/layers/convolutional\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/test_utils.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/save_load_utils.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/conv_utils.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/jaccard.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/dssim.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/crf_losses.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/metrics\n",
            "copying build/lib/keras_contrib/metrics/crf_accuracies.py -> build/bdist.linux-x86_64/egg/keras_contrib/metrics\n",
            "copying build/lib/keras_contrib/metrics/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/metrics\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/yogi.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/padam.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/ftml.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/lars.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/preprocessing\n",
            "copying build/lib/keras_contrib/preprocessing/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/preprocessing\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/regularizers\n",
            "copying build/lib/keras_contrib/regularizers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/regularizers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/constraints\n",
            "copying build/lib/keras_contrib/constraints/clip.py -> build/bdist.linux-x86_64/egg/keras_contrib/constraints\n",
            "copying build/lib/keras_contrib/constraints/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/constraints\n",
            "copying build/lib/keras_contrib/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/activations\n",
            "copying build/lib/keras_contrib/activations/squash.py -> build/bdist.linux-x86_64/egg/keras_contrib/activations\n",
            "copying build/lib/keras_contrib/activations/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/activations\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/conll2000.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/pascal_voc.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/coco.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/initializers\n",
            "copying build/lib/keras_contrib/initializers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/initializers\n",
            "copying build/lib/keras_contrib/initializers/convaware.py -> build/bdist.linux-x86_64/egg/keras_contrib/initializers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/activations.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/optimizers.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/metrics.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/regularizers.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/swish.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/sinerelu.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/srelu.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/pelu.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/normalization/instancenormalization.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/normalization/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/normalization/groupnormalization.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/core.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "copying build/lib/keras_contrib/layers/crf.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "copying build/lib/keras_contrib/layers/capsule.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "copying build/lib/keras_contrib/layers/convolutional/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "copying build/lib/keras_contrib/layers/convolutional/cosineconvolution2d.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "copying build/lib/keras_contrib/layers/convolutional/subpixelupscaling.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/densenet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/resnet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/nasnet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/wide_resnet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/wrappers\n",
            "copying build/lib/keras_contrib/wrappers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/wrappers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/cyclical_learning_rate.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/dead_relu_detector.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/tensorboard.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/snapshot.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/cntk_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/tensorflow_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/numpy_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/theano_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/save_load_utils.py to save_load_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/conv_utils.py to conv_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/jaccard.py to jaccard.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/dssim.py to dssim.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/crf_losses.py to crf_losses.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/metrics/crf_accuracies.py to crf_accuracies.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/metrics/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/yogi.py to yogi.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/padam.py to padam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/ftml.py to ftml.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/lars.py to lars.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/preprocessing/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/regularizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/constraints/clip.py to clip.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/constraints/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/activations/squash.py to squash.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/activations/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/conll2000.py to conll2000.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/pascal_voc.py to pascal_voc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/coco.py to coco.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/initializers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/initializers/convaware.py to convaware.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/activations.py to activations.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/optimizers.py to optimizers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/metrics.py to metrics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/regularizers.py to regularizers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/swish.py to swish.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/sinerelu.py to sinerelu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/srelu.py to srelu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/pelu.py to pelu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization/instancenormalization.py to instancenormalization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization/groupnormalization.py to groupnormalization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/core.py to core.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/crf.py to crf.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/capsule.py to capsule.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional/cosineconvolution2d.py to cosineconvolution2d.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional/subpixelupscaling.py to subpixelupscaling.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/densenet.py to densenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/resnet.py to resnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/nasnet.py to nasnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/wide_resnet.py to wide_resnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/wrappers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/cyclical_learning_rate.py to cyclical_learning_rate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/dead_relu_detector.py to dead_relu_detector.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/tensorboard.py to tensorboard.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/snapshot.py to snapshot.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/cntk_backend.py to cntk_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/tensorflow_backend.py to tensorflow_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/numpy_backend.py to numpy_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/theano_backend.py to theano_backend.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tf_keras_contrib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tf_keras_contrib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tf_keras_contrib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tf_keras_contrib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tf_keras_contrib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/tf_keras_contrib-2.0.8-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing tf_keras_contrib-2.0.8-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/tf_keras_contrib-2.0.8-py3.6.egg\n",
            "Copying tf_keras_contrib-2.0.8-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "tf-keras-contrib 2.0.8 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/tf_keras_contrib-2.0.8-py3.6.egg\n",
            "Processing dependencies for tf-keras-contrib==2.0.8\n",
            "Finished processing dependencies for tf-keras-contrib==2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ihsALFkr3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Layer, InputSpec, DepthwiseConv2D, Conv2D, BatchNormalization, Add, ReLU, LeakyReLU, ZeroPadding2D, Activation, LeakyReLU\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import os\n",
        "import gc\n",
        "from glob import glob\n",
        "from itertools import product\n",
        "from random import choice\n",
        "\n",
        "from imageio import imwrite\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfj_Aj-2xoun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Not sure what this does\n",
        "\"\"\"\n",
        "\n",
        "class ReflectionPadding2D(Layer):\n",
        "  def __init__(self, padding=(1, 1), **kwargs):\n",
        "    super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "    padding = tuple(padding)\n",
        "    self.padding = ((0, 0), padding, padding, (0, 0))\n",
        "    self.input_spec = [InputSpec(ndim=4)]\n",
        "\n",
        "  def compute_output_shape(self, s):\n",
        "    return s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3]\n",
        "\n",
        "  def call(self, x):\n",
        "    return tf.pad(x, self.padding, \"REFLECT\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK9cK5baxVPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_padding(pad_type, padding):\n",
        "  if pad_type == 'reflect':\n",
        "    return ReflectionPadding2D(padding)\n",
        "  elif pad_type == 'constant':\n",
        "    return ZeroPadding2D(padding)\n",
        "  else:\n",
        "    raise ValueError(f'Invalid padding type: {pad_type}')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz0hHKqpzh_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_norm(norm_type):\n",
        "  if norm_type == 'instance':\n",
        "    return tfa.layers.InstanceNormalization()\n",
        "  elif norm_type == 'batch':\n",
        "    return BatchNormalization()\n",
        "  else:\n",
        "    raise ValueError(f'Invalid norm type: {norm_type}')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iZX8QK3uHXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FlatConv(Model):\n",
        "  def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               norm_type='instance',\n",
        "               pad_type='constant',\n",
        "               **kwargs):\n",
        "    super(FlatConv, self).__init__(name='FlatConv')\n",
        "    \"\"\"\n",
        "    # assuming stride=1, remaining size will be (W - kernel_size) + 1 * (8 - kernel_size) + 1 so must add back (kernel_size - 1) // 2\n",
        "    \"\"\"\n",
        "    padding = (kernel_size - 1) // 2\n",
        "    padding = (padding, padding)\n",
        "\n",
        "    self.model = Sequential([\n",
        "                             get_padding(pad_type, padding),\n",
        "                             Conv2D(filters, kernel_size),\n",
        "                             get_norm(norm_type),\n",
        "                             ReLU()\n",
        "    ])\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    return self.model(x, training=training)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE0WxKQf13Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(Model):\n",
        "  def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               stride=1,\n",
        "               norm_type='instance',\n",
        "               pad_type='constant',\n",
        "               **kwargs):\n",
        "    super(ConvBlock, self).__init__(name='ConvBlock')\n",
        "  \n",
        "    padding = (kernel_size - 1) // 2\n",
        "    padding = (padding, padding)\n",
        "\n",
        "    self.model = Sequential([\n",
        "                              get_padding(pad_type, padding),\n",
        "                              Conv2D(filters, kernel_size, strides=stride),\n",
        "                              get_padding(pad_type, padding),\n",
        "                              Conv2D(filters, kernel_size),\n",
        "                              get_norm(norm_type),\n",
        "                              ReLU()\n",
        "    ])\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    return self.model(x, training=training)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la4ZE9gc2FXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(Model):\n",
        "  def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               norm_type='instance',\n",
        "               pad_type='constant',\n",
        "               **kwargs):\n",
        "    super(ResBlock, self).__init__(name='ResBlock')\n",
        "    \n",
        "    padding = (kernel_size - 1) // 2\n",
        "    padding = (padding, padding)\n",
        "\n",
        "    self.model = Sequential([\n",
        "                             get_padding(pad_type, padding),\n",
        "                             Conv2D(filters, kernel_size),\n",
        "                             get_norm(norm_type),\n",
        "                             ReLU(),\n",
        "                             get_padding(pad_type, padding),\n",
        "                             Conv2D(filters, kernel_size),\n",
        "                             get_norm(norm_type)\n",
        "    ])\n",
        "\n",
        "    self.add = Add()\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    return self.add([self.model(x, training=training), x])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMYs6f90E3cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UpSampleConv(Model):\n",
        "  def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               norm_type='instance',\n",
        "               pad_type='constant',\n",
        "               **kwargs):\n",
        "    super(UpSampleConv, self).__init__(name='UpSampleConv')\n",
        "    self.model = ConvBlock(filters, kernel_size, 1, norm_type, pad_type)\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    \"\"\"\n",
        "    In downsampling, we can get away with reducing size in half by setting stride=2\n",
        "    In upsample, we need to do directly resize the images\n",
        "    \"\"\"\n",
        "    x = tf.keras.backend.resize_images(x, 2, 2, \"channels_last\", 'bilinear')\n",
        "    return self.model(x, training=training)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oewDUupJMvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(Model):\n",
        "  def __init__(self,\n",
        "               norm_type='instance',\n",
        "               pad_type='constant',\n",
        "               base_filters=64,\n",
        "               num_resblocks=8):\n",
        "    super(Generator, self).__init__(name='Generator')\n",
        "    self.flat_conv = FlatConv(filters=base_filters, kernel_size=7, norm_type=norm_type, pad_type=pad_type)\n",
        "    self.down_conv1 = ConvBlock(mid_filters=base_filters, filters=base_filters * 2, kernel_size=3, stride=2, norm_type=norm_type, pad_type=pad_type)\n",
        "    self.down_conv2 = ConvBlock(mid_filters=base_filters, filters=base_filters * 4, kernel_size=3, stride=2, norm_type=norm_type, pad_type=pad_type)\n",
        "    self.res_blocks = Sequential([ResBlock(filters=base_filters * 4, kernel_size=3, norm_type=norm_type, pad_type=pad_type) for _ in range(num_resblocks)])\n",
        "    self.up_conv1 = UpSampleConv(filters=base_filters * 2, kernel_size=3, norm_type=norm_type, pad_type=pad_type)\n",
        "    self.up_conv2 = UpSampleConv(filters=base_filters, kernel_size=3, norm_type=norm_type, pad_type=pad_type)\n",
        "\n",
        "    padding = (3, 3)\n",
        "    self.final_conv = Sequential([\n",
        "                                  get_padding(pad_type, padding),\n",
        "                                  Conv2D(filters=3, kernel_size=7),\n",
        "                                  Activation('tanh')\n",
        "    ])\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    x = self.flat_conv(x, training=training)\n",
        "    x = self.down_conv1(x, training=training)\n",
        "    x = self.down_conv2(x, training=training)\n",
        "    x = self.res_blocks(x, training=training)\n",
        "    x = self.up_conv1(x, training=training)\n",
        "    x = self.up_conv2(x, training=training)\n",
        "    x = self.final_conv(x, training=training)\n",
        "    return x\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return tf.TensorShape(input_shape)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHXDGNumInDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StridedConv(Model):\n",
        "  def __init__(self,\n",
        "               filters=64,\n",
        "               lrelu_alpha=0.2,\n",
        "               pad_type='constant',\n",
        "               norm_type='batch',\n",
        "               **kwargs):\n",
        "    super(StridedConv, self).__init__(name='StridedConv')\n",
        "\n",
        "    self.model = Sequential([\n",
        "                             get_padding(pad_type, (1, 1)),\n",
        "                             Conv2D(filters, 3, strides=(2, 2)),\n",
        "                             LeakyReLU(lrelu_alpha),\n",
        "                             get_padding(pad_type, (1, 1)),\n",
        "                             Conv2D(filters * 2, 3),\n",
        "                             get_norm(norm_type),\n",
        "                             LeakyReLU(lrelu_alpha)\n",
        "    ])\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    return self.model(x, training=training)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kFbWRkqPg92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(Model):\n",
        "  def __init__(self,\n",
        "               base_filters=32,\n",
        "               lrelu_alpha=0.2,\n",
        "               pad_type='reflect',\n",
        "               norm_type='batch'\n",
        "               ):\n",
        "    super(Discriminator, self).__init__(name='Discriminator')\n",
        "    if pad_type =='reflect':\n",
        "      self.flat_pad = ReflectionPadding2D()\n",
        "    elif pad_type == 'constant':\n",
        "      self.flat_pad = ZeroPadding2D()\n",
        "    else:\n",
        "      raise ValueError(f'Invalid pad_type {pad_type}')\n",
        "\n",
        "    self.flat_conv = Conv2D(base_filters, 3)\n",
        "    self.flat_lru = LeakyReLU(lrelu_alpha)\n",
        "    self.strided_conv1 = StridedConv(base_filters * 2, lrelu_alpha, pad_type, norm_type)\n",
        "    self.strided_conv2 = StridedConv(base_filters * 4, lrelu_alpha, pad_type, norm_type)\n",
        "    self.conv2 = Conv2D(base_filters * 8, 3)\n",
        "\n",
        "    if norm_type == 'instance':\n",
        "      self.norm = InstanceNormalization()\n",
        "    elif norm_type == 'batch':\n",
        "      self.norm = BatchNormalization()\n",
        "\n",
        "    self.lrelu = LeakyReLU(lrelu_alpha)\n",
        "    self.final_conv = Conv2D(1, 3)\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    x = self.flat_pad(x, training=training)\n",
        "    x = self.flat_conv(x, training=training)\n",
        "    x = self.flat_lru(x, training=training)\n",
        "    x = self.strided_conv1(x, training=training)\n",
        "    x = self.strided_conv2(x, training=training)\n",
        "    x = self.conv2(x, training=training)\n",
        "    x = self.norm(x, training=training)\n",
        "    x = self.lrelu(x, training=training)\n",
        "    x = self.final_conv(x, training=training)\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt0h1_3iPh1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "5dfc69b6-496c-495b-8398-86bf822ca87a"
      },
      "source": [
        "shape = (1, 256, 256, 3)\n",
        "nx = np.random.rand(*shape).astype(np.float32)\n",
        "t = tf.keras.Input(shape=nx.shape[1:], batch_size=nx.shape[0])\n",
        "print(nx.shape)\n",
        "d = Discriminator()\n",
        "out = d(t)\n",
        "d.summary()\n",
        "print(f\"Input  Shape: {t.shape}\")\n",
        "print(f\"Output Shape: {out.shape}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 256, 256, 3)\n",
            "Model: \"Discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reflection_padding2d (Reflec (1, 258, 258, 3)          0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (1, 256, 256, 32)         896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (1, 256, 256, 32)         0         \n",
            "_________________________________________________________________\n",
            "StridedConv (StridedConv)    (1, 128, 128, 128)        92864     \n",
            "_________________________________________________________________\n",
            "StridedConv (StridedConv)    (1, 64, 64, 256)          443776    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (1, 62, 62, 256)          590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (1, 62, 62, 256)          1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (1, 62, 62, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (1, 60, 60, 1)            2305      \n",
            "=================================================================\n",
            "Total params: 1,130,945\n",
            "Trainable params: 1,129,665\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n",
            "Input  Shape: (1, 256, 256, 3)\n",
            "Output Shape: (1, 60, 60, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRQIMlR3POcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg_model(input_size):\n",
        "  input_shape = (input_size, input_size, 3)\n",
        "  base_model = VGG19(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "  conv_block = base_model.get_layer('block4_conv3').output\n",
        "  new_conv_block = Conv2D(512, (3, 3), activation='linear', padding='same', name='block4_conv4')(conv_block)\n",
        "  vgg = Model(inputs=base_model.input, outputs=new_conv_block)\n",
        "  vgg.load_weights(os.path.expanduser(os.path.join(\"~\", \".keras\", \"models\", \"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")), by_name=True)\n",
        "  return vgg"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDdS3qpNKCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(x):\n",
        "  # Do not really understand these details but they ultimately build the gram matrix so we can add texture details from the style image onto content image from the VGG output\n",
        "  shape_x = tf.shape(x)\n",
        "  b = shape_x[0]\n",
        "  c = shape_x[3]\n",
        "  x = tf.reshape(x, [b, -1, c])\n",
        "  return tf.matmul(tf.transpose(x, [0, 2, 1]), x) / tf.cast((tf.size(x) // b), tf.float32)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtB28wCmLwOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_loss(input_images, generated_images):\n",
        "  return mae(input_images, generated_images)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0LDWKImL-P9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_loss(input_images, generated_images):\n",
        "  return mae(gram_matrix(input_images), gram_matrix(generated_images))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7W15hI_Hoo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output, smooth_output):\n",
        "  # real_loss = d_loss_obj([1 for _ in range(real_output)], real_output)\n",
        "  # fake_loss = d_loss_obj([0 for _ in range(fake_output)], fake_output)\n",
        "  # smooth_loss = d_loss_obj([0 for _ in range(smooth_output)], smooth_output)\n",
        "  real_loss = d_loss_obj(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = d_loss_obj(tf.zeros_like(fake_output), fake_output)\n",
        "  smooth_loss = d_loss_obj(tf.zeros_like(smooth_output), smooth_output)\n",
        "  total_loss = real_loss + fake_loss + smooth_loss\n",
        "  return real_loss, fake_loss, smooth_loss, total_loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXiotLRNKGfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_adversarial_loss(fake_output):\n",
        "  # return g_loss_obj([1 for _ in range(fake_output)], fake_output)\n",
        "  return g_loss_obj(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwlpFgkRS7Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(source_images, target_images, generated_images, fake_output):\n",
        "    g_adv_loss = g_adv_lambda * generator_adversarial_loss(fake_output)\n",
        "    vgg_generated_images = vgg(generated_images)\n",
        "    c_loss = content_lambda * content_loss(vgg(source_images), vgg_generated_images)\n",
        "    s_loss = style_lambda * style_loss(vgg(target_images[:vgg_generated_images.shape[0]]), vgg_generated_images)\n",
        "    g_total_loss = g_adv_loss + c_loss + s_loss\n",
        "    return g_adv_loss, c_loss, s_loss, g_total_loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oti_qy3lGwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(source_images, target_images, smooth_images, generator, discriminator, g_optimizer, d_optimizer):\n",
        "  with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "\n",
        "    print(f'Get output')\n",
        "    # get output\n",
        "    real_output = discriminator(target_images, training=True)\n",
        "    generated_images = generator(source_images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "    smooth_output = discriminator(smooth_images, training=True)\n",
        "\n",
        "    print(f'Calculate loss')\n",
        "    # calculate loss\n",
        "    d_real_loss, d_fake_loss, d_smooth_loss, d_total_loss = discriminator_loss(real_output, fake_output, smooth_output)\n",
        "    g_adv_loss, g_content_loss, g_style_loss, g_total_loss = generator_loss(source_images, target_images, generated_images, fake_output)\n",
        "\n",
        "    print(f'Calculate gradient')\n",
        "    # calculate gradient\n",
        "    d_grads = d_tape.gradient(d_total_loss, discriminator.trainable_variables)\n",
        "    g_grads = g_tape.gradient(g_total_loss, generator.trainable_variables)\n",
        "\n",
        "    print(f'Apply gradients')\n",
        "    # apply gradients with optimizer\n",
        "    d_optimizer.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
        "    g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
        "\n",
        "    output = [\n",
        "      real_output, \n",
        "      generated_images, \n",
        "      fake_output, \n",
        "      smooth_output, \n",
        "      d_real_loss.numpy(), \n",
        "      d_fake_loss.numpy(), \n",
        "      d_smooth_loss.numpy(), \n",
        "      d_total_loss.numpy(), \n",
        "      g_adv_loss.numpy(), \n",
        "      g_content_loss.numpy(), \n",
        "      g_style_loss.numpy(), \n",
        "      g_total_loss.numpy()\n",
        "    ]\n",
        "    return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LUvi2LKYHjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_resize(x):\n",
        "  size = choice(sizes)\n",
        "  return tf.image.resize(x, (size, size))\n",
        "\n",
        "def image_processing(file_name, is_train=True):\n",
        "  crop_size = input_size\n",
        "\n",
        "  if is_train:\n",
        "    crop_size += 32\n",
        "\n",
        "  img = tf.io.read_file(file_name)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "  if is_train:\n",
        "    sizes = tf.cast(crop_size * tf.random.uniform([2], 0.9, 1.1), tf.int32)\n",
        "    shape = tf.shape(img)[:2]\n",
        "    sizes = tf.minimum(sizes, shape)\n",
        "    img = tf.image.random_crop(img, (sizes[0], sizes[1], 3))\n",
        "    img = tf.image.random_flip_left_right(img)\n",
        "  \n",
        "  img = tf.image.resize(img, (crop_size, crop_size))\n",
        "  img = tf.cast(img, tf.float32) / 127.5 - 1\n",
        "  return img\n",
        "\n",
        "def preprocess(file_name):\n",
        "  return random_resize(image_processing(file_name, True))\n",
        "\n",
        "def get_dataset(dataset_name, domain, _type, batch_size):\n",
        "  files = glob(os.path.join(data_dir, dataset_name, f'{_type}{domain}', '*'))\n",
        "  num_files = len(files)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(files)\n",
        "  dataset = dataset.apply(tf.data.experimental.shuffle_and_repeat(num_files))\n",
        "  dataset = dataset.apply(tf.data.experimental.map_and_batch(preprocess, batch_size))\n",
        "  steps = int(np.ceil(num_files / batch_size))\n",
        "  return iter(dataset), steps"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYdnkk1pUXVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(generator=None):\n",
        "  generator_dir = os.path.join(model_dir, 'generator')\n",
        "  discriminator_dir = os.path.join(model_dir, 'discriminator')\n",
        "\n",
        "  dataset_source, steps_per_epoch = get_dataset(dataset_name=dataset_name, domain=source_domain, _type='train', batch_size=batch_size)\n",
        "  dataset_target, _ = get_dataset(dataset_name=dataset_name, domain=target_domain, _type='train', batch_size=batch_size)\n",
        "  dataset_smooth, _ = get_dataset(dataset_name=dataset_name, domain=smooth_domain, _type='train', batch_size=batch_size)\n",
        "\n",
        "  g_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=.5)\n",
        "  d_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=.5)\n",
        "\n",
        "  if generator is None:\n",
        "    generator = Generator(base_filters=64)\n",
        "    generator(tf.keras.Input(shape=(input_size, input_size, 3), batch_size=batch_size))\n",
        "\n",
        "  discriminator = Discriminator(base_filters=32)\n",
        "  discriminator(tf.keras.Input(shape=(input_size, input_size, 3), batch_size=batch_size))\n",
        "\n",
        "  # save info\n",
        "  d_checkpoint = tf.train.Checkpoint(discriminator=discriminator)\n",
        "  g_checkpoint = tf.train.Checkpoint(generator=generator)\n",
        "\n",
        "  try:\n",
        "    status = d_checkpoint.restore(tf.train.latest_checkpoint(discriminator_dir))\n",
        "    trained_epochs = d_checkpoint.save_counter.numpy()\n",
        "    print(f'Discriminator checkpoint {trained_epochs} found')\n",
        "  except AssertionError:\n",
        "    print('No discriminator checkpoint')\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    status = g_checkpoint.restore(tf.train.latest_checkpoint(generator_dir))\n",
        "    trained_epochs = g_checkpoint.save_counter.numpy()\n",
        "    print(f'Generator checkpoint {trained_epochs} found')\n",
        "  except AssertionError:\n",
        "    print('No generator checkpoint')\n",
        "    pass\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for step in tqdm(range(steps_per_epoch), desc=f'Train {epoch} / {epochs}', total=steps_per_epoch):\n",
        "      source_images = dataset_source.next()\n",
        "      target_images = dataset_source.next()\n",
        "      smooth_images = dataset_source.next()\n",
        "\n",
        "      print(f'Step: {step}')\n",
        "      real_output, generated_images, fake_output, smooth_output, d_real_loss, d_fake_loss, d_smooth_loss, d_total_loss, g_adv_loss, g_content_loss, g_style_loss, g_total_loss = train_step(source_images, target_images, smooth_images, generator, discriminator, g_optimizer, d_optimizer)\n",
        "\n",
        "    d_checkpoint.save(file_prefix=os.path.join(discriminator_dir, 'discriminator'))\n",
        "    g_checkpoint.save(file_prefix=os.path.join(generator_dir, 'generator'))\n",
        "    \n",
        "    # update log info\n",
        "    logger['d_real_loss'].append(d_real_loss)\n",
        "    logger['d_fake_loss'].append(d_fake_loss)\n",
        "    logger['d_smooth_loss'].append(d_smooth_loss)\n",
        "    logger['d_total_loss'].append(d_total_loss)\n",
        "    logger['g_adv_loss'].append(g_adv_loss)\n",
        "    logger['g_content_loss'].append(g_content_loss)\n",
        "    logger['g_style_loss'].append(g_style_loss)\n",
        "    logger['g_total_loss'].append(g_total_loss)\n",
        "\n",
        "    discriminator.save_weights(discriminator_dir)\n",
        "    generator.save_weights(generator_dir)\n",
        "    gc.collect()\n",
        "\n",
        "  del dataset_source, dataset_target, dataset_smooth\n",
        "  gc.collect()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQHVCBPAQbmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrain_step(input_images, generator, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # get output\n",
        "    generated_images = generator(input_images)\n",
        "\n",
        "    # calculate loss\n",
        "    vgg_generated_images = vgg(generated_images)\n",
        "    loss = content_lambda * content_loss(vgg(input_images), vgg_generated_images)\n",
        "\n",
        "    # calculate gradient\n",
        "    grads = tape.gradient(loss, generator.trainable_variables)\n",
        "\n",
        "    # apply gradient\n",
        "    optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
        "\n",
        "    return loss.numpy()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1DcCaQBWgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrain_generator():\n",
        "  pretrain_dir = os.path.join(model_dir, 'pretrain')\n",
        "\n",
        "  dataset_source, steps_per_epoch = get_dataset(dataset_name=dataset_name, domain=source_domain, _type='train', batch_size=batch_size)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=.5)\n",
        "\n",
        "  generator = Generator(base_filters=64)\n",
        "  generator(tf.keras.Input(shape=(input_size, input_size, 3), batch_size=batch_size))\n",
        "\n",
        "  # save info\n",
        "  checkpoint = tf.train.Checkpoint(generator=generator)\n",
        "\n",
        "  trained_epochs = 0\n",
        "\n",
        "  try:\n",
        "    status = checkpoint.restore(tf.train.latest_checkpoint(pretrain_dir))\n",
        "    trained_epochs = checkpoint.save_counter.numpy()\n",
        "    print(f'Pretrain checkpoint {trained_epochs} found')\n",
        "  except AssertionError:\n",
        "    print('No pretrain checkpoint')\n",
        "    pass\n",
        "\n",
        "  pretrain_epochs = pt_epochs - trained_epochs\n",
        "\n",
        "  for epoch in range(pretrain_epochs):\n",
        "    for step in tqdm(range(steps_per_epoch), desc=f'Train {epoch} / {pretrain_epochs}', total=steps_per_epoch):\n",
        "      source_images = dataset_source.next()\n",
        "\n",
        "      loss = pretrain_step(source_images, generator, optimizer)\n",
        "\n",
        "\n",
        "    logger['pretrain_loss'].append(loss)\n",
        "    checkpoint.save(file_prefix=os.path.join(pretrain_dir, 'generator'))\n",
        "    generator.save_weights(pretrain_dir)\n",
        "    gc.collect() # collect garbage often\n",
        "\n",
        "  del dataset_source      \n",
        "\n",
        "  gc.collect()\n",
        "\n",
        "  return generator"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOlrAkgeEmK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_logs():\n",
        "  num_loss_values = len(loss_values)\n",
        "\n",
        "  i = 0\n",
        "  leng = math.ceil(math.sqrt(num_loss_values))\n",
        "\n",
        "  fig, axs = plt.subplots(nrows=leng, ncols=leng)\n",
        "  axs = axs.flatten()\n",
        "\n",
        "  for row in range(leng):\n",
        "    if i == num_loss_values:\n",
        "      break\n",
        "    for col in range(leng):\n",
        "      if i == num_loss_values:\n",
        "        break\n",
        "      loss_val = loss_values[i]\n",
        "\n",
        "      train_epochs = np.arange(0, len(logger[loss_val]))\n",
        "      axs[i].plot(train_epochs, logger[loss_val])\n",
        "      axs[i].set_xlabel('Epoch')\n",
        "      axs[i].set_ylabel('Loss')\n",
        "      axs[i].set_title(loss_val)\n",
        "      i += 1\n",
        "  \n",
        "  # fig.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAMZZdsmIiDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "g_loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\n",
        "g_adv_lambda = 1.\n",
        "content_lambda = 10.\n",
        "style_lambda = 1.\n",
        "input_size = 256\n",
        "sizes = [input_size - 32, input_size, input_size + 32]\n",
        "vgg = vgg_model(input_size)\n",
        "pt_epochs = 10\n",
        "epochs = 10\n",
        "dataset_name = '/content/drive/My Drive/pg-toons/naruto_aladdin_small'\n",
        "data_dir = './'\n",
        "source_domain = 'A'\n",
        "target_domain = 'B'\n",
        "smooth_domain = 'B_smooth'\n",
        "batch_size = 1\n",
        "model_dir = '/content/drive/My Drive/pg-toons/my_models'\n",
        "loss_values = ['pretrain_loss', 'd_real_loss', 'd_fake_loss', 'd_smooth_loss', 'd_total_loss', 'g_adv_loss', 'g_content_loss', 'g_style_loss', 'g_total_loss']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tRiSwaiYAnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a91fc437-785a-4953-c3ae-7cdb52ae2796"
      },
      "source": [
        "try:\n",
        "  logger = np.load(os.path.join(model_dir, 'logs.npy'), allow_pickle='TRUE').item()\n",
        "except:\n",
        "  logger = {loss_val: [] for loss_val in loss_values}\n",
        "generator = pretrain_generator()\n",
        "np.save(os.path.join(model_dir, 'logs.npy'), logger)\n",
        "train(generator)\n",
        "np.save(os.path.join(model_dir, 'logs.npy'), logger)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-5b12b6a7a6f5>:32: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From <ipython-input-22-5b12b6a7a6f5>:33: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTrain 0 / 10:   0%|          | 0/711 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pretrain checkpoint 0 found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train 0 / 10: 100%|██████████| 711/711 [02:44<00:00,  4.33it/s]\n",
            "Train 1 / 10: 100%|██████████| 711/711 [02:28<00:00,  4.78it/s]\n",
            "Train 2 / 10: 100%|██████████| 711/711 [02:28<00:00,  4.80it/s]\n",
            "Train 3 / 10: 100%|██████████| 711/711 [02:27<00:00,  4.81it/s]\n",
            "Train 4 / 10: 100%|██████████| 711/711 [02:25<00:00,  4.87it/s]\n",
            "Train 5 / 10: 100%|██████████| 711/711 [02:26<00:00,  4.84it/s]\n",
            "Train 6 / 10: 100%|██████████| 711/711 [02:26<00:00,  4.85it/s]\n",
            "Train 7 / 10: 100%|██████████| 711/711 [02:28<00:00,  4.78it/s]\n",
            "Train 8 / 10: 100%|██████████| 711/711 [02:28<00:00,  4.78it/s]\n",
            "Train 9 / 10: 100%|██████████| 711/711 [02:26<00:00,  4.85it/s]\n",
            "Train 0 / 10:   0%|          | 0/711 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator checkpoint 0 found\n",
            "Generator checkpoint 0 found\n",
            "Step: 0\n",
            "Get output\n",
            "Calculate loss\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "Calculate gradient\n",
            "Apply gradients\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTrain 0 / 10:   0%|          | 1/711 [00:01<19:29,  1.65s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step: 1\n",
            "Get output\n",
            "Calculate loss\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "Calculate gradient\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTrain 0 / 10:   0%|          | 2/711 [00:02<15:13,  1.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Apply gradients\n",
            "Step: 2\n",
            "Get output\n",
            "Calculate loss\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "Calculate gradient\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTrain 0 / 10:   0%|          | 3/711 [00:02<12:16,  1.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Apply gradients\n",
            "Step: 3\n",
            "Get output\n",
            "Calculate loss\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "Calculate gradient\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTrain 0 / 10:   1%|          | 4/711 [00:03<10:09,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Apply gradients\n",
            "Step: 4\n",
            "Get output\n",
            "Calculate loss\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "Calculate gradient\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTrain 0 / 10:   1%|          | 5/711 [00:03<08:47,  1.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Apply gradients\n",
            "Step: 5\n",
            "Get output\n",
            "Calculate loss\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"input_2:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (1, 288, 288, 3).\n",
            "Calculate gradient\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train 0 / 10:   1%|          | 6/711 [00:04<07:59,  1.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Apply gradients\n",
            "Step: 6\n",
            "Get output\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2fde02803230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_values\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logs.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-a3161a3ba436>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Step: {step}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mreal_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_real_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_fake_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_smooth_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_adv_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_content_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_style_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_total_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0md_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'discriminator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-d95bf9fcfe11>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(source_images, target_images, smooth_images, generator, discriminator, g_optimizer, d_optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mreal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msmooth_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-852bc811f380>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided_conv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    216\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   2795\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2796\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[0;32m-> 2797\u001b[0;31m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    670\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m    671\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BiasAdd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         tld.op_callbacks, value, bias, \"data_format\", data_format)\n\u001b[0m\u001b[1;32m    673\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mDPFgHwcv4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "cfce822c-b9be-4a1a-ac4f-92f7e48e349d"
      },
      "source": [
        "plot_logs()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j91kIBjFk-rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(os.path.join(model_dir, 'logs.npy'), logger)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aCjUlXKloKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}